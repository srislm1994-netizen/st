# -*- coding: utf-8 -*-
"""Welcome To Colab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb
"""

# 1. Imports
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error

# 2. Synthetic multivariate time series dataset
def generate_multivariate_dataset(n_samples=2000):
    t = np.arange(n_samples)
    feature1 = np.sin(0.02 * t) + np.random.normal(0, 0.1, n_samples)
    feature2 = np.cos(0.02 * t) + np.random.normal(0, 0.1, n_samples)
    feature3 = np.sin(0.04 * t) + np.random.normal(0, 0.1, n_samples)
    feature4 = np.cos(0.04 * t) + np.random.normal(0, 0.1, n_samples)
    feature5 = feature1 + feature2 + np.random.normal(0, 0.05, n_samples)
    target = feature1 * 0.5 + feature3 * 0.5 + np.random.normal(0, 0.1, n_samples)
    df = pd.DataFrame({
        'feature1': feature1,
        'feature2': feature2,
        'feature3': feature3,
        'feature4': feature4,
        'feature5': feature5,
        'target': target
    })
    return df

df = generate_multivariate_dataset()
feature_cols = ['feature1', 'feature2', 'feature3', 'feature4', 'feature5']

# 3. Preprocessing and DataLoader
scaler = StandardScaler()
df[feature_cols] = scaler.fit_transform(df[feature_cols])
df['target'] = scaler.fit_transform(df[['target']])

class TimeSeriesDataset(Dataset):
    def __init__(self, df, feature_cols, target_col, seq_length=32):
        self.X = df[feature_cols].values
        self.y = df[target_col].values
        self.seq_length = seq_length

    def __len__(self):
        return len(self.X) - self.seq_length

    def __getitem__(self, idx):
        return (
            torch.tensor(self.X[idx:idx+self.seq_length], dtype=torch.float32),
            torch.tensor(self.y[idx+self.seq_length], dtype=torch.float32)
        )

seq_length = 32
train_size = int(0.8 * (len(df)-seq_length))
train_ds = TimeSeriesDataset(df[:train_size+seq_length], feature_cols, 'target', seq_length)
test_ds = TimeSeriesDataset(df[train_size:], feature_cols, 'target', seq_length)
train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)
test_loader = DataLoader(test_ds, batch_size=64, shuffle=False)

# 4. Positional Encoding layer for time series
class PositionalEncoding(nn.Module):
    def __init__(self, d_model, max_len):
        super().__init__()
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        self.pe = pe.unsqueeze(0)

    def forward(self, x):
        x = x + self.pe[:, :x.size(1)]
        return x

# 5. Transformer Model
class TimeSeriesTransformer(nn.Module):
    def __init__(self, feature_dim, d_model=64, nhead=4, num_layers=2, seq_length=32):
        super().__init__()
        self.input_fc = nn.Linear(feature_dim, d_model)
        self.pos_encoder = PositionalEncoding(d_model, seq_length)
        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead)
        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)
        self.fc_out = nn.Linear(d_model, 1)

    def forward(self, x):
        x = self.input_fc(x)
        x = self.pos_encoder(x)
        x = x.permute(1, 0, 2)  # Transformer expects (sequence, batch, features)
        out = self.transformer_encoder(x)
        out = out[-1, :, :]  # Use last time step
        return self.fc_out(out).squeeze()

# 6. LSTM benchmark model
class SimpleLSTM(nn.Module):
    def __init__(self, feature_dim, hidden_dim=64, num_layers=1):
        super().__init__()
        self.lstm = nn.LSTM(feature_dim, hidden_dim, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_dim, 1)

    def forward(self, x):
        out, _ = self.lstm(x)
        out = out[:, -1, :]
        return self.fc(out).squeeze()

# 7. Training and Evaluation functions
def train_model(model, train_loader, val_loader, epochs=30, lr=1e-3):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')
    criterion = nn.MSELoss()

    for epoch in range(epochs):
        model.train()
        for X, y in train_loader:
            X, y = X.to(device), y.to(device)
            optimizer.zero_grad()
            out = model(X)
            loss = criterion(out, y)
            loss.backward()
            nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()
        # Validate
        val_loss = evaluate_model(model, val_loader)
        scheduler.step(val_loss)
        print(f"Epoch {epoch+1}/{epochs}, Val Loss: {val_loss:.4f}")

def evaluate_model(model, data_loader):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    model.eval()
    preds, targets = [], []
    with torch.no_grad():
        for X, y in data_loader:
            X, y = X.to(device), y.to(device)
            out = model(X)
            preds.append(out.cpu().numpy())
            targets.append(y.cpu().numpy())
    preds = np.concatenate(preds)
    targets = np.concatenate(targets)
    rmse = np.sqrt(mean_squared_error(targets, preds))
    mae = mean_absolute_error(targets, preds)
    print(f"RMSE: {rmse:.4f}, MAE: {mae:.4f}")
    return rmse

# 8. Instantiate and train models
transformer = TimeSeriesTransformer(len(feature_cols), seq_length=seq_length)
lstm = SimpleLSTM(len(feature_cols))

print("Training Transformer...")
train_model(transformer, train_loader, test_loader, epochs=30, lr=1e-3)

print("\nTraining LSTM Benchmark...")
train_model(lstm, train_loader, test_loader, epochs=30, lr=1e-3)

print("\nFinal Evaluation: Transformer")
evaluate_model(transformer, test_loader)

print("\nFinal Evaluation: LSTM")
evaluate_model(lstm, test_loader)